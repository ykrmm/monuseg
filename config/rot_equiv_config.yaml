training:    
    auto_lr: false
    learning_rate: 0.1
    scheduler: True
    wd : 0.0002
    moment: 0.8 
    batch_size: 17 
    n_epochs: 50
    benchmark: True
    num_classes: 2 


equiv_training:
  pi_rotate: True # Rotation equivariance is only angle 90,180,270
  Loss: 'KL' # Loss used for equivariance cost function (KL or CE)
  multi_task: True # Multi task training dataset_equiv = dataset_supervised
  gamma: 0.9 # Loss balancing parameters: gamma*loss_equiv + (1-gamma)*loss_sup
  eval_every: 30 # Eval Performances on different input rotation angles every n epochs.


model_config:
  model: 'FCN'
  pretrained: False # pretrained fcn 
  eval_angle: False
  aji: True


data_augmentation: 
  rotate: True
  scale: True
  size_img: 256
  size_crop: 240
  angle_max: 360 # Max angle for the random rotations

loader_gpu:
  nw: 4 # Num workers
  pm: True # Pin memory
  gpu: 2 # Device to use 
  rot_cpu: True # Rotation on CPU to use less GPU memory 

dataset: 
  split: False
  split_ratio: 0.1 # Percentage of supervised data 
  dataroot_monuseg: '/share/DEEPLEARNING/datasets/monuseg'
  entire_image: True # Eval on the complete image 1000x1000 size
  target_size: '256' # target size used for spliting images
  stride: '128' #Stride used for spliting images


save_config: 
  model_name: 'rot_equiv_monuseg'
  save_dir: '/share/homes/karmimy/equiv/save_model/rot_equiv_monuseg'
  save_all_ep: False
  save_best: True # If true will only save the best epoch model


